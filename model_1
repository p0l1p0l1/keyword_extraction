{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Xc-fCeWMNvNZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707152710699,"user_tz":-60,"elapsed":72262,"user":{"displayName":"Polina Poliaeva","userId":"03175933134917434029"}},"outputId":"461a185e-8152-486e-9e8a-2c0675c94771"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.16.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n","Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n","Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.1)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.16.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.23.5)\n","Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.15)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.20.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.2)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (10.0.1)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2023.11.17)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.26.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (2.4.0)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2.8.2)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2023.12.25)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.23.5)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.4)\n","Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.1)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n","Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu121)\n","Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.26.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.3)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.1.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.11.17)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n"]}],"source":["!pip install datasets\n","!pip install evaluate\n","!pip install accelerate -U\n","!pip install sacrebleu\n","!pip install transformers[torch]"]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModel\n","from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n","from transformers import TrainingArguments, Trainer\n","from transformers import DataCollatorForSeq2Seq\n","from datasets import load_dataset, DatasetDict\n","import evaluate\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","import torch\n","from torch.utils.tensorboard import SummaryWriter"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fw8BehXtN1iu","executionInfo":{"status":"ok","timestamp":1707158118976,"user_tz":-60,"elapsed":28182,"user":{"displayName":"Polina Poliaeva","userId":"03175933134917434029"}},"outputId":"87aafa7b-4fa3-419b-eaae-0b56c491543b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["model_name = \"t5-small\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer)\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DNrbcEomN_T3","executionInfo":{"status":"ok","timestamp":1707158126068,"user_tz":-60,"elapsed":7113,"user":{"displayName":"Polina Poliaeva","userId":"03175933134917434029"}},"outputId":"76398d99-68b6-4bae-e235-39f37b461577"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["whole_dataset = load_dataset(\"sunhaozhepy/ag_news_keywords\")\n","scifi_dataset = whole_dataset.filter(lambda example: example[\"label\"]==3)\n","small_dataset = DatasetDict(\n","    train=scifi_dataset['train'].shuffle(seed=25).select(range(128)),\n","    valid=scifi_dataset['train'].shuffle(seed=25).select(range(128, 160)),\n","    example=scifi_dataset['train'].shuffle(seed=25).select(range(160, 168)),\n","    test=scifi_dataset['test'].shuffle(seed=25).select(range(32))\n",")\n","\n","def prepare_data(tokenizer, dts_name, dts=small_dataset):\n","  data = dts[dts_name].map(lambda x:\n","      {'input_ids': tokenizer.encode(x[\"text\"], padding='max_length', truncation=True),\n","       'labels': tokenizer(x[\"keywords\"], return_tensors=\"pt\")[\"input_ids\"][0]}\n","  )\n","  data = data.remove_columns([\"text\", \"label\", \"keywords\"])\n","  return data\n","\n","train_data = prepare_data(tokenizer, \"train\")\n","valid_data = prepare_data(tokenizer, \"valid\")\n","example_data = prepare_data(tokenizer, \"example\")\n","test_data = small_dataset[\"test\"][\"text\"]\n","test_data_tokenized = prepare_data(tokenizer, \"test\")\n","test_data_tokenized = test_data_tokenized.remove_columns([\"labels\"])\n","test_data_tokenized"],"metadata":{"id":"Bo2yuTk1OQyb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707158129390,"user_tz":-60,"elapsed":3372,"user":{"displayName":"Polina Poliaeva","userId":"03175933134917434029"}},"outputId":"4cc97967-71d8-425f-f6a4-d3939a3001d5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['input_ids'],\n","    num_rows: 32\n","})"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["mt_metrics = evaluate.combine(\n","    [\"bleu\", \"chrf\"], force_prefix=True)\n","\n","def compute_metrics(pred):\n","    labels_ids = pred.label_ids\n","    pred_ids = pred.predictions\n","\n","    predictions = tokenizer.batch_decode(pred_ids)#, skip_special_tokens=True) <- the trainer runs into devision by zero error if enabled :/\n","\n","    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n","    references = tokenizer.batch_decode(labels_ids)#, skip_special_tokens=True)\n","\n","    outputs = mt_metrics.compute(predictions=predictions,\n","                             references=references)\n","\n","    return outputs"],"metadata":{"id":"9T_EDJhCOZhi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["training_args = Seq2SeqTrainingArguments(\n","    output_dir='/content/drive/MyDrive/2024W Computational Linguistics/project/model_1_files/checkpoints',\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    logging_steps=1,\n","    num_train_epochs=20,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    predict_with_generate=True,\n","    load_best_model_at_end=True\n","    metric_for_best_model=\"chr_f_score\",\n",")"],"metadata":{"id":"UfiQsEk9Ofjt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=train_data.with_format(\"torch\"),\n","    eval_dataset=valid_data.with_format(\"torch\"),\n","    compute_metrics=compute_metrics\n",")\n","\n","trainer.train()\n","trainer.save_model('/content/drive/MyDrive/2024W Computational Linguistics/project/model_1_files')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"igxErz3rOnGs","executionInfo":{"status":"ok","timestamp":1707158923992,"user_tz":-60,"elapsed":219568,"user":{"displayName":"Polina Poliaeva","userId":"03175933134917434029"}},"outputId":"72735bfb-9679-426e-c82e-6988567a6821"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='160' max='160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [160/160 03:36, Epoch 20/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu Bleu</th>\n","      <th>Bleu Precisions</th>\n","      <th>Bleu Brevity Penalty</th>\n","      <th>Bleu Length Ratio</th>\n","      <th>Bleu Translation Length</th>\n","      <th>Bleu Reference Length</th>\n","      <th>Chr F Score</th>\n","      <th>Chr F Char Order</th>\n","      <th>Chr F Word Order</th>\n","      <th>Chr F Beta</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>4.799300</td>\n","      <td>4.279509</td>\n","      <td>0.484898</td>\n","      <td>[0.5105724600309438, 0.48610382800209756, 0.4768, 0.4671730873575692]</td>\n","      <td>1.000000</td>\n","      <td>1.507776</td>\n","      <td>1939</td>\n","      <td>1286</td>\n","      <td>53.488635</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>4.113200</td>\n","      <td>3.665587</td>\n","      <td>0.204740</td>\n","      <td>[0.45537757437070936, 0.34323040380047504, 0.29259259259259257, 0.2532133676092545]</td>\n","      <td>0.624130</td>\n","      <td>0.679627</td>\n","      <td>874</td>\n","      <td>1286</td>\n","      <td>26.445864</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>3.853300</td>\n","      <td>3.174016</td>\n","      <td>0.165383</td>\n","      <td>[0.5089163237311386, 0.38593974175035867, 0.3142857142857143, 0.2575039494470774]</td>\n","      <td>0.465771</td>\n","      <td>0.566874</td>\n","      <td>729</td>\n","      <td>1286</td>\n","      <td>27.468806</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>2.486100</td>\n","      <td>2.750115</td>\n","      <td>0.186422</td>\n","      <td>[0.581267217630854, 0.4438040345821326, 0.3564954682779456, 0.2873015873015873]</td>\n","      <td>0.462388</td>\n","      <td>0.564541</td>\n","      <td>726</td>\n","      <td>1286</td>\n","      <td>32.929014</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>2.899800</td>\n","      <td>2.465883</td>\n","      <td>0.272521</td>\n","      <td>[0.626360338573156, 0.5069182389937107, 0.42988204456094364, 0.37209302325581395]</td>\n","      <td>0.574062</td>\n","      <td>0.643079</td>\n","      <td>827</td>\n","      <td>1286</td>\n","      <td>38.101830</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>2.298600</td>\n","      <td>2.283547</td>\n","      <td>0.306354</td>\n","      <td>[0.6422121896162528, 0.5163934426229508, 0.4343065693430657, 0.3721518987341772]</td>\n","      <td>0.636693</td>\n","      <td>0.688958</td>\n","      <td>886</td>\n","      <td>1286</td>\n","      <td>41.174732</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>2.486900</td>\n","      <td>2.180442</td>\n","      <td>0.469662</td>\n","      <td>[0.7270087124878993, 0.6273726273726273, 0.5593395252837977, 0.5080042689434365]</td>\n","      <td>0.782769</td>\n","      <td>0.803266</td>\n","      <td>1033</td>\n","      <td>1286</td>\n","      <td>51.286899</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>2.180300</td>\n","      <td>2.115622</td>\n","      <td>0.517467</td>\n","      <td>[0.7198549410698096, 0.6349206349206349, 0.575553416746872, 0.5292949354518371]</td>\n","      <td>0.847121</td>\n","      <td>0.857698</td>\n","      <td>1103</td>\n","      <td>1286</td>\n","      <td>53.735280</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>1.932200</td>\n","      <td>2.066925</td>\n","      <td>0.531135</td>\n","      <td>[0.7118794326241135, 0.6332116788321168, 0.5780075187969925, 0.5348837209302325]</td>\n","      <td>0.869297</td>\n","      <td>0.877138</td>\n","      <td>1128</td>\n","      <td>1286</td>\n","      <td>55.017340</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>2.035900</td>\n","      <td>2.022611</td>\n","      <td>0.568754</td>\n","      <td>[0.7393939393939394, 0.6607301869991096, 0.6031164069660861, 0.559017941454202]</td>\n","      <td>0.892776</td>\n","      <td>0.898134</td>\n","      <td>1155</td>\n","      <td>1286</td>\n","      <td>57.254303</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>1.631500</td>\n","      <td>1.985785</td>\n","      <td>0.595943</td>\n","      <td>[0.7432659932659933, 0.6686851211072664, 0.6147686832740213, 0.5741758241758241]</td>\n","      <td>0.920819</td>\n","      <td>0.923795</td>\n","      <td>1188</td>\n","      <td>1286</td>\n","      <td>58.982572</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>2.182800</td>\n","      <td>1.955771</td>\n","      <td>0.605287</td>\n","      <td>[0.7474916387959866, 0.6735395189003437, 0.6201413427561837, 0.5809090909090909]</td>\n","      <td>0.927511</td>\n","      <td>0.930016</td>\n","      <td>1196</td>\n","      <td>1286</td>\n","      <td>59.566043</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>2.095600</td>\n","      <td>1.938557</td>\n","      <td>0.602831</td>\n","      <td>[0.7523245984784447, 0.6794092093831451, 0.6255585344057194, 0.5850965961361545]</td>\n","      <td>0.916616</td>\n","      <td>0.919907</td>\n","      <td>1183</td>\n","      <td>1286</td>\n","      <td>59.815519</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>1.753800</td>\n","      <td>1.929415</td>\n","      <td>0.618922</td>\n","      <td>[0.7646566164154104, 0.6901893287435457, 0.636283185840708, 0.5947176684881603]</td>\n","      <td>0.925842</td>\n","      <td>0.928460</td>\n","      <td>1194</td>\n","      <td>1286</td>\n","      <td>61.153030</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>1.796900</td>\n","      <td>1.918784</td>\n","      <td>0.626017</td>\n","      <td>[0.7693588676103247, 0.6937553464499572, 0.6394019349164468, 0.5972850678733032]</td>\n","      <td>0.931672</td>\n","      <td>0.933904</td>\n","      <td>1201</td>\n","      <td>1286</td>\n","      <td>61.451551</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>1.787800</td>\n","      <td>1.907424</td>\n","      <td>0.656533</td>\n","      <td>[0.7814784727863525, 0.7080900750625522, 0.6546700942587832, 0.613215859030837]</td>\n","      <td>0.956304</td>\n","      <td>0.957232</td>\n","      <td>1231</td>\n","      <td>1286</td>\n","      <td>63.253049</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>1.341400</td>\n","      <td>1.898649</td>\n","      <td>0.665494</td>\n","      <td>[0.7859450726978998, 0.7131011608623549, 0.6601362862010222, 0.6190893169877408]</td>\n","      <td>0.961970</td>\n","      <td>0.962675</td>\n","      <td>1238</td>\n","      <td>1286</td>\n","      <td>63.945139</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>1.838200</td>\n","      <td>1.892650</td>\n","      <td>0.665496</td>\n","      <td>[0.7872168284789643, 0.7142857142857143, 0.6612627986348123, 0.6201754385964913]</td>\n","      <td>0.960354</td>\n","      <td>0.961120</td>\n","      <td>1236</td>\n","      <td>1286</td>\n","      <td>63.979753</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>1.815300</td>\n","      <td>1.889620</td>\n","      <td>0.667759</td>\n","      <td>[0.7853107344632768, 0.7125103562551781, 0.6629787234042553, 0.6237970253718286]</td>\n","      <td>0.962777</td>\n","      <td>0.963453</td>\n","      <td>1239</td>\n","      <td>1286</td>\n","      <td>63.695924</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>1.756800</td>\n","      <td>1.888675</td>\n","      <td>0.667759</td>\n","      <td>[0.7853107344632768, 0.7125103562551781, 0.6629787234042553, 0.6237970253718286]</td>\n","      <td>0.962777</td>\n","      <td>0.963453</td>\n","      <td>1239</td>\n","      <td>1286</td>\n","      <td>63.695924</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","Trainer is attempting to log a value of \"[0.5105724600309438, 0.48610382800209756, 0.4768, 0.4671730873575692]\" of type <class 'list'> for key \"eval/bleu_precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","Trainer is attempting to log a value of \"[0.45537757437070936, 0.34323040380047504, 0.29259259259259257, 0.2532133676092545]\" of type <class 'list'> for key \"eval/bleu_precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","Trainer is attempting to log a value of \"[0.5089163237311386, 0.38593974175035867, 0.3142857142857143, 0.2575039494470774]\" of type <class 'list'> for key \"eval/bleu_precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","Trainer is attempting to log a value of \"[0.581267217630854, 0.4438040345821326, 0.3564954682779456, 0.2873015873015873]\" of type <class 'list'> for key \"eval/bleu_precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","Trainer is attempting to log a value of \"[0.626360338573156, 0.5069182389937107, 0.42988204456094364, 0.37209302325581395]\" of type <class 'list'> for key \"eval/bleu_precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","Trainer is attempting to log a value of \"[0.6422121896162528, 0.5163934426229508, 0.4343065693430657, 0.3721518987341772]\" of type <class 'list'> for key \"eval/bleu_precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","Trainer is attempting to log a value of \"[0.7270087124878993, 0.6273726273726273, 0.5593395252837977, 0.5080042689434365]\" of type <class 'list'> for key \"eval/bleu_precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","Trainer is attempting to log a value of \"[0.7198549410698096, 0.6349206349206349, 0.575553416746872, 0.5292949354518371]\" of type <class 'list'> for key \"eval/bleu_precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","Trainer is attempting to log a value of \"[0.7118794326241135, 0.6332116788321168, 0.5780075187969925, 0.5348837209302325]\" of type <class 'list'> for key \"eval/bleu_precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","Trainer is attempting to log a value of \"[0.7393939393939394, 0.6607301869991096, 0.6031164069660861, 0.559017941454202]\" of type <class 'list'> for key \"eval/bleu_precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","Trainer is attempting to log a value of \"[0.7432659932659933, 0.6686851211072664, 0.6147686832740213, 0.5741758241758241]\" of type <class 'list'> for key \"eval/bleu_precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","Trainer is attempting to log a value of \"[0.7474916387959866, 0.6735395189003437, 0.6201413427561837, 0.5809090909090909]\" of type <class 'list'> for key \"eval/bleu_precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","Trainer is attempting to log a value of \"[0.7523245984784447, 0.6794092093831451, 0.6255585344057194, 0.5850965961361545]\" of type <class 'list'> for key \"eval/bleu_precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","Trainer is attempting to log a value of \"[0.7646566164154104, 0.6901893287435457, 0.636283185840708, 0.5947176684881603]\" of type <class 'list'> for key \"eval/bleu_precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","Trainer is attempting to log a value of \"[0.7693588676103247, 0.6937553464499572, 0.6394019349164468, 0.5972850678733032]\" of type <class 'list'> for key \"eval/bleu_precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","Trainer is attempting to log a value of \"[0.7814784727863525, 0.7080900750625522, 0.6546700942587832, 0.613215859030837]\" of type <class 'list'> for key \"eval/bleu_precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","Trainer is attempting to log a value of \"[0.7859450726978998, 0.7131011608623549, 0.6601362862010222, 0.6190893169877408]\" of type <class 'list'> for key \"eval/bleu_precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","Trainer is attempting to log a value of \"[0.7872168284789643, 0.7142857142857143, 0.6612627986348123, 0.6201754385964913]\" of type <class 'list'> for key \"eval/bleu_precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","Trainer is attempting to log a value of \"[0.7853107344632768, 0.7125103562551781, 0.6629787234042553, 0.6237970253718286]\" of type <class 'list'> for key \"eval/bleu_precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","Trainer is attempting to log a value of \"[0.7853107344632768, 0.7125103562551781, 0.6629787234042553, 0.6237970253718286]\" of type <class 'list'> for key \"eval/bleu_precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"]}]},{"cell_type":"code","source":["predictions = trainer.predict(example_data)\n","print(predictions.predictions.shape, predictions.label_ids.shape)\n","print(predictions.predictions, predictions.label_ids)\n","pr = tokenizer.batch_decode(predictions.label_ids, skip_special_tokens=True)\n","print(tokenizer.batch_decode(example_data[\"input_ids\"], skip_special_tokens=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":644},"id":"GU3InKciOvIl","executionInfo":{"status":"ok","timestamp":1707162059465,"user_tz":-60,"elapsed":991,"user":{"displayName":"Polina Poliaeva","userId":"03175933134917434029"}},"outputId":"f765ab67-07ab-4d12-f8c2-018a4eb1a42e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(8, 20) (8, 20)\n","[[    0 26290    11 12422     6    11   432     8  1150    31     7     3\n","      9  7557     1     0     0     0     0     0]\n"," [    0 30148     6  3726    18 13529   308     6  2104     7    16  3581\n","      1     0     0     0     0     0     0     0]\n"," [    0  5266  1998     6  2803     6  5266  1998     1     0     0     0\n","      0     0     0     0     0     0     0     0]\n"," [    0  2803     6   126 13214     6 21759  5471     1     0     0     0\n","      0     0     0     0     0     0     0     0]\n"," [    0 20132 16118   210     6 19052  9034     7     1     0     0     0\n","      0     0     0     0     0     0     0     0]\n"," [    0 26094     9     9     6  3746     6  1218  1042    18     7   210\n","      9  5341     6  1614  3392     3     5     1]\n"," [    0 13017   287     6   220  2247 19764 15703    26   663     6     1\n","      0     0     0     0     0     0     0     0]\n"," [    0  1473     6  1284  2100   467     6  1284  6913     7     6  1284\n","   1031     1     0     0     0     0     0     0]] [[ 2750     6 26290    11 12422     6  1261  3040   276    88  3114    35\n","    106     1     0     0     0     0     0     0]\n"," [  445  3073     6 30148     6  3726    18 13529   308     1     0     0\n","      0     0     0     0     0     0     0     0]\n"," [ 2803     6  2269    18 29100   380     6  2344 11641  4709     1     0\n","      0     0     0     0     0     0     0     0]\n"," [ 2803     6 13214     6  1586   748     1     0     0     0     0     0\n","      0     0     0     0     0     0     0     0]\n"," [20132     3   189     9   210     6  1252 14811     6 27656     7     1\n","      0     0     0     0     0     0     0     0]\n"," [11392    53  9036     6 26094     9     9     6 20255  3535    86    89\n","   1007  1194     1     0     0     0     0     0]\n"," [13017   287     6  3751  4864     6 23795 13762     1     0     0     0\n","      0     0     0     0     0     0     0     0]\n"," [ 1473     6   671   467  4514     6  1157 29139     1     0     0     0\n","      0     0     0     0     0     0     0     0]]\n","[\"Download, Peel and Stick, and All the World's a Gallery Inspired by graffiti, posters and the communal culture of the Web, stickers are gaining wide attention as an artistic phenomenon.\", 'NEC, Toshiba add HD-DVD to PCs in 2005 NEC plans to start selling desktop PCs equipped with HD-DVD drives at the end of 2005, the company announced. Slimmed-down versions of the drives will be added to laptops in 2006.', 'MS strategy pushes it to cross-platform support COPENHAGEN - Microsoft Corp. wrapped up its IT Forum in Copenhagen this week by singing the praises of new management tools that are part of a long-term vision for reducing IT complexity. But behind its more vocal announcements there emerged another significant tune, one that suggested that the software maker will have to be more willing to play with platforms from other companies in order to deliver its new strategy.', 'Microsoft #39;s new mice get touchy Microsoft is introducing a new line of keyboards and mice, including some with fingerprint readers that lets users scan a finger instead of having to enter a log-in name and password when accessing online services or logging on to the PC.', 'Fast Arctic Thaw Threatens People, Polar Bears Global warming is heating the Arctic almost twice as fast as the rest of the planet in a thaw that threatens millions of livelihoods and could wipe', 'Recording Industry, Kazaa Square Off (AP) AP - Lawyers for Australia\\'s recording industry branded the popular Kazaa computer file-swapping network \"an engine of copyright piracy to a degree of magnitude never before seen\" as they launched a court battle Monday to shut down its activities.', 'Update 2: Broadcom Lowers 3Q Revenue Guidance Semiconductor maker Broadcom Corp. lowered its third-quarter revenue guidance, saying customers who make cable and satellite set-top boxes over-ordered its chips in the first half of the year.', 'China Bans Video Game for Breach of Sovereignty China, sensitive about issues of national sovereignty, has banned a computer sports game that classifies Taiwan, Hong Kong, Macau and Tibet as countries and has threatened to fine Web sites that supply the game and net cafes that let']\n"]}]},{"cell_type":"code","source":["[i for i in pr if i not in small_dataset[\"example\"][\"keywords\"]]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sm3k3-DYxz0T","executionInfo":{"status":"ok","timestamp":1707161983279,"user_tz":-60,"elapsed":295,"user":{"displayName":"Polina Poliaeva","userId":"03175933134917434029"}},"outputId":"638ecdce-f4ea-4c5a-f88b-203d332863a4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["trainer.evaluate(example_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":387},"id":"JSmezh3mPbtB","executionInfo":{"status":"ok","timestamp":1707159232556,"user_tz":-60,"elapsed":471,"user":{"displayName":"Polina Poliaeva","userId":"03175933134917434029"}},"outputId":"db867bbb-70f6-4942-8801-caa73f7e2be9"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1/1 : < :]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Trainer is attempting to log a value of \"[0.8074324324324325, 0.7256944444444444, 0.6678571428571428, 0.6286764705882353]\" of type <class 'list'> for key \"eval/bleu_precisions\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 1.697526454925537,\n"," 'eval_bleu_bleu': 0.6785836173021433,\n"," 'eval_bleu_precisions': [0.8074324324324325,\n","  0.7256944444444444,\n","  0.6678571428571428,\n","  0.6286764705882353],\n"," 'eval_bleu_brevity_penalty': 0.9635198762133231,\n"," 'eval_bleu_length_ratio': 0.9641693811074918,\n"," 'eval_bleu_translation_length': 296,\n"," 'eval_bleu_reference_length': 307,\n"," 'eval_chr_f_score': 57.36081850327452,\n"," 'eval_chr_f_char_order': 6,\n"," 'eval_chr_f_word_order': 0,\n"," 'eval_chr_f_beta': 2,\n"," 'eval_runtime': 0.6125,\n"," 'eval_samples_per_second': 13.062,\n"," 'eval_steps_per_second': 1.633,\n"," 'epoch': 20.0}"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["fine_tuned_model = AutoModelForSeq2SeqLM.from_pretrained(\"/content/drive/MyDrive/2024W Computational Linguistics/project/model_1_files/checkpoints/checkpoint-160\")\n","model_inputs = tokenizer(test_data, padding=True, truncation=True, return_tensors='pt').input_ids\n","decoder_input_ids = tokenizer(test_data, padding=True, truncation=True, return_tensors='pt').input_ids\n","outputs = fine_tuned_model(input_ids=model_inputs, decoder_input_ids=decoder_input_ids, output_hidden_states=True)\n","keyword_embeddings = fine_tuned_model.generate(model_inputs)\n","keywords_result = [tokenizer.decode(emb, skip_special_tokens=True, clean_up_tokenization_spaces=False) for emb in keyword_embeddings]"],"metadata":{"id":"ptHOkC6uwrtE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["keywords_result[9]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"1ghB9b3rysVi","executionInfo":{"status":"ok","timestamp":1707162246131,"user_tz":-60,"elapsed":329,"user":{"displayName":"Polina Poliaeva","userId":"03175933134917434029"}},"outputId":"173247f0-dc0f-4e1b-e57c-8c02701bf613"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Disney takes sides in battle for next generation DVD (AFP) AFP - Hollywood movie power'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["test_data[9]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"1DY3UOtbzBh4","executionInfo":{"status":"ok","timestamp":1707162248521,"user_tz":-60,"elapsed":387,"user":{"displayName":"Polina Poliaeva","userId":"03175933134917434029"}},"outputId":"dec77e4a-de50-4bd6-a5a5-c046b0ab5522"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"Disney takes sides in battle for next generation DVD (AFP) AFP - Hollywood movie powerhouse Walt Disney has taken sides with Japan's Sony Corp. in a bitter battle between studios to define a technical standard for next generation DVDs, it said.\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["path = \"/content/drive/MyDrive/2024W Computational Linguistics/project/model_1_files/results_vis_checkpoint-160\"\n","layer=0\n","if not os.path.exists(path):\n","  os.mkdir(path)\n","\n","while layer in range(len(outputs.decoder_hidden_states)):\n","  if not os.path.exists(path+'/layer_' + str(layer)):\n","    os.mkdir(path+'/layer_' + str(layer))\n","\n","  example = 0\n","  tensors = []\n","  labels = []\n","\n","  while example in range(len(outputs.decoder_hidden_states[layer])):\n","    sp_token_position = 0\n","    for token in model_inputs[example]:\n","      if token != 1:\n","        sp_token_position += 1\n","      else:\n","        tensor = outputs.decoder_hidden_states[layer][example][sp_token_position]\n","        tensors.append(tensor)\n","        break\n","\n","    label = [test_data[example], str(keywords_result[example])]\n","    labels.append(label)\n","    example +=1\n","\n","  writer=SummaryWriter(path+'/layer_' + str(layer))\n","  writer.add_embedding(torch.stack(tensors), metadata=labels, metadata_header=['Text','Keywords'])\n","\n","  layer+=1"],"metadata":{"id":"RV7d0B70pbtB"},"execution_count":null,"outputs":[]}]}